{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo para geração do indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordInfo:\n",
    "    'Classe que guarda informações sobre a palavra, como documentos em que ocorre, tf em cada documento e calculo de idf'\n",
    "\n",
    "    def __init__(self, word) : # Contrutor da classe recebe apenas a palavra em questão\n",
    "        self.word = word\n",
    "        self.idf = 0\n",
    "        self.docs = {} # Dicionario que mapeia doc_id ao tf da palavra\n",
    "\n",
    "    def found(self, doc_id) : # Metodo que realiza a contagem do tf da palavra\n",
    "        if(doc_id in self.docs) : # Se o doc_id está mapeado, incrementa-o\n",
    "            self.docs[doc_id] += 1\n",
    "        else :\n",
    "            self.docs[doc_id] = 1 # Caso contrario, define-o como 1\n",
    "            \n",
    "    def calculateIDF(self, totaldocs) : # Metodo de calculo do idf, recebendo o total de documentos\n",
    "        df = len(self.docs) # Numero de documentos em que a palavra ocorre \n",
    "        if (df > 0) :\n",
    "            self.idf = math.log(((totaldocs + 1)/df))\n",
    "            \n",
    "    def getIds(self) : # Metodo que retorna todos os doc_ids em que a palavra ocorre\n",
    "        return list(self.docs.keys())\n",
    "    \n",
    "    def getTf(self, doc_id) : # Metodo que retorna o tf da palavra em um documento, ou 0 caso não ocorra\n",
    "        return self.docs.get(doc_id, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabela = pandas.read_csv('estadao_noticias_eleicao.csv')\n",
    "tabela.fillna('', inplace=True) # Preenchendo os campos vazios da tabela com ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapa = {} # Dicionario/Mapa que representa o indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documentos = {} # Dicionario que guarda os documentos e seus tamanhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, linha in tabela.iterrows() : # Iterando sobre as noticias no arquivo\n",
    "    id = linha['idNoticia'] # Recuperando o idNoticia da noticia atual\n",
    "    texto = nltk.word_tokenize(linha['titulo'] + ' ' + linha['subTitulo'] + ' ' + linha['conteudo']) # Tokenização do texto\n",
    "    documentos[id] = len(texto) # Mapeamento do documento com seu tamanho\n",
    "    for palavra in texto: # Iterando sobre as palavras na Noticia\n",
    "        if (palavra not in string.punctuation): # Só ocorre o mapeamento se a palavra não é uma pontuação\n",
    "            if (palavra.lower() not in mapa) : # Se a palavra ainda não foi mapeada, mapeia-a\n",
    "                mapa[palavra.lower()] = WordInfo(palavra.lower())\n",
    "            mapa[palavra.lower()].found(id) # Contabiliza a ocorrencia da palavra no documento atual\n",
    "\n",
    "for k in mapa.keys() : # Laço para realizar o calculo dos idfs de cada palavra mapeada\n",
    "    mapa[k].calculateIDF(len(documentos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de Consultas Booleanas(And, Or e geral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def searchAnd(palavra1, palavra2) :\n",
    "    docs1 = mapa[palavra1.lower()].getIds() # Recupera todos as noticias em que \"palavra1\" ocorreu\n",
    "    docs2 = mapa[palavra2.lower()].getIds() # Recupera todos as noticias em que \"palavra2\" ocorreu\n",
    "    result = set() # Cria um conjunto vazio\n",
    "    result.update(docs1) # Preenche o conjunto com os ids das noticias que \"palavra1\" aparece\n",
    "    result = result.intersection(docs2) # Mantem no conjunto apenas os ids que as duas palavras ocorrem.\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def searchOr(palavra1, palavra2) :\n",
    "    docs1 = mapa[palavra1.lower()].getIds() # Recupera todos as noticias em que \"palavra1\" ocorreu\n",
    "    docs2 = mapa[palavra2.lower()].getIds() # Recupera todos as noticias em que \"palavra2\" ocorreu\n",
    "    result = set() # Cria um conjunto vazio\n",
    "    result.update(docs1) # Preenche o conjunto com os ids das noticias que \"palavra1\" aparece\n",
    "    result.update(docs2) # Preenche o conjunto com os ids das noticias que \"palavra2\" aparece, por ser conjunto as duplicadas são eliminadas\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(consulta) :\n",
    "    partes = consulta.split(' ')\n",
    "    if (len(partes) < 2) : # Se a consulta só tem uma palavra\n",
    "        return mapa[partes[0].lower()].getIds() # Recupera os ids que a palavra aparece\n",
    "    elif (partes[1].upper() == 'AND') : # Se é uma consulta AND\n",
    "        return searchAnd(partes[0], partes[2]) # Chama a função de consulta AND\n",
    "    elif (partes[1].upper() == 'OR') : # Se é uma consulta OR\n",
    "        return searchOr(partes[0], partes[2]) # Chama a função de consulta OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de Consultas Vetoriais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_binaria(consulta) :\n",
    "    palavras = consulta.split(' ') # Quebrando a consulta em palavras\n",
    "    relevant_docs = set(mapa[palavras[0]].getIds()) # Inicia o conjunto de documentos relevantes\n",
    "    # Laço que realiza interseção dos conjuntos, para mantes apenas documentos em que todas as palavras a consulta ocorre\n",
    "    for i in range(1, len(palavras)) :\n",
    "        relevant_docs = relevant_docs.intersection(set(mapa[palavras[i]].getIds()))\n",
    "    # Como é busca binaria, apenas retorna os primeiros 5 documentos que contem todas as palavras\n",
    "    return list(relevant_docs)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_tf(consulta) :\n",
    "    palavras = consulta.split(' ') # Quebrando a consulta em palavras\n",
    "    relevant_docs = set(mapa[palavras[0]].getIds()) # Inicia o conjunto de documentos relevantes\n",
    "    # Laço que realiza interseção dos conjuntos, para mantes apenas documentos em que todas as palavras a consulta ocorre\n",
    "    for i in range(1, len(palavras)) :\n",
    "        relevant_docs = relevant_docs.intersection(set(mapa[palavras[i]].getIds()))\n",
    "    result = [] # Lista que será gerado o resultado\n",
    "    for doc_id in relevant_docs : # Para cada documento relevante\n",
    "        scores = [mapa[w].getTf(doc_id) for w in palavras] # Obtem os tfs de cada palavra da consulta\n",
    "        # Cria uma tupla (score, doc_id) somando os tfs obtidos e coloca na lista\n",
    "        score_id = (sum(scores), doc_id)\n",
    "        result.append(score_id)\n",
    "    # Ordena do maior para o menor, considerando apenas o primeiro elemento da tupla para ordenar (o score)\n",
    "    result = sorted(result, reverse=True, key=lambda tup: tup[0]) \n",
    "    result = [t[1] for t in result] # A lista passa a ser apenas dos doc_ids\n",
    "    return result[:5] # Retorna os 5 primeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_tfidf(consulta) :\n",
    "    palavras = consulta.split(' ') # Quebrando a consulta em palavras\n",
    "    relevant_docs = set(mapa[palavras[0]].getIds()) # Inicia o conjunto de documentos relevantes\n",
    "    # Laço que realiza interseção dos conjuntos, para mantes apenas documentos em que todas as palavras a consulta ocorre\n",
    "    for i in range(1, len(palavras)) :\n",
    "        relevant_docs = relevant_docs.intersection(set(mapa[palavras[i]].getIds()))\n",
    "    result = [] # Lista que será gerado o resultado\n",
    "    for doc_id in relevant_docs : # Para cada documento relevante\n",
    "        scores = [] # Lista para guardar os scores de cada palavra da consulta\n",
    "        for w in palavras : # Calcula tf * idf de cada palavra da consulta e adiciona na lista\n",
    "            m_palavra = mapa[w]\n",
    "            w_score = m_palavra.getTf(doc_id) * m_palavra.idf\n",
    "            scores.append(w_score)\n",
    "        # Cria uma tupla (score, doc_id) somando os resultados obtidos e coloca na lista\n",
    "        score_id = (sum(scores), doc_id)\n",
    "        result.append(score_id)\n",
    "    # Ordena do maior para o menor, considerando apenas o primeiro elemento da tupla para ordenar (o score)\n",
    "    result = sorted(result, reverse=True, key=lambda tup: tup[0])\n",
    "    result = [t[1] for t in result] # A lista passa a ser apenas dos doc_ids\n",
    "    return result[:5] # Retorna os 5 primeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_bm25(consulta) :\n",
    "    k = 6 # 6 foi o valor de K que maximizou o resultado da função mapk\n",
    "    palavras = consulta.split(' ') # Quebrando a consulta em palavras\n",
    "    relevant_docs = set(mapa[palavras[0]].getIds()) # Inicia o conjunto de documentos relevantes\n",
    "    # Laço que realiza interseção dos conjuntos, para mantes apenas documentos em que todas as palavras a consulta ocorre\n",
    "    for i in range(1, len(palavras)) :\n",
    "        relevant_docs = relevant_docs.intersection(set(mapa[palavras[i]].getIds()))\n",
    "    result = [] # Lista que será gerado o resultado\n",
    "    for doc_id in relevant_docs : # Para cada documento relevante\n",
    "        scores = [] # Lista para guardar os scores de cada palavra da consulta\n",
    "        for w in palavras : # Calcula tf*(k+1)/(tf + k) * idf de cada palavra da consulta e adiciona na lista\n",
    "            m_palavra = mapa[w]\n",
    "            tf = m_palavra.getTf(doc_id)\n",
    "            w_score = (tf*(k+1))/(tf + k) * m_palavra.idf\n",
    "            scores.append(w_score)\n",
    "        # Cria uma tupla (score, doc_id) somando os resultados obtidos e coloca na lista\n",
    "        score_id = (sum(scores), doc_id)\n",
    "        result.append(score_id)\n",
    "    # Ordena do maior para o menor, considerando apenas o primeiro elemento da tupla para ordenar (o score)\n",
    "    result = sorted(result, reverse=True, key=lambda tup: tup[0])\n",
    "    result = [t[1] for t in result] # A lista passa a ser apenas dos doc_ids\n",
    "    return result[:5] # Retorna os 5 primeiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação Buscas Vetoriais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da função de comparação, Leitura do gabarito e realização das consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "gabarito = pandas.read_csv('gabarito.csv')\n",
    "# Transformando a string lida em lista de listas\n",
    "gabarito_busca_binaria = list(gabarito.busca_binaria)\n",
    "gabarito_tf = list(gabarito.tf)\n",
    "gabarito_tfidf = list(gabarito.tfidf)\n",
    "gabarito_bm25 = list(gabarito.bm25)\n",
    "for i in range(len(gabarito_tf)) :\n",
    "    gabarito_busca_binaria[i] = ast.literal_eval(gabarito_busca_binaria[i])\n",
    "    gabarito_tf[i] = ast.literal_eval(gabarito_tf[i])\n",
    "    gabarito_tfidf[i] = ast.literal_eval(gabarito_tfidf[i])\n",
    "    gabarito_bm25[i] = ast.literal_eval(gabarito_bm25[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaria_result, tf_result, tfidf_result, bm25_result = [], [], [], []\n",
    "for consulta in gabarito.str_busca :\n",
    "    binaria_result.append(busca_binaria(consulta))\n",
    "    tf_result.append(busca_tf(consulta))\n",
    "    tfidf_result.append(busca_tfidf(consulta))\n",
    "    bm25_result.append(busca_bm25(consulta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mapk Busca Binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(gabarito_busca_binaria, binaria_result, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mapk Busca TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(gabarito_tf, tf_result, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mapk TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7606666666666666"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(gabarito_tfidf, tfidf_result, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mapk BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84266666666666656"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(gabarito_bm25, bm25_result, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Do melhor ao pior, como se saíram os modelos? Justifique sua resposta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparado ao gabarito, os modelos que mais se aproximaram da resposta esperada foram:\n",
    "    1. Vetor binario e TF\n",
    "    2. BM25\n",
    "    3. TF-IDF\n",
    "Existem, para algumas consultas, nos modelos (BM25 e TF-IDF) alguns documentos que aparecem como melhores que os demais, mas que não estão no gabarito ou estão em uma posição inferior, talvez por algum problema de precedência nas formulas dos 2. Num geral, acredito que o pior seja o modelo de busca binária, pois apenas verifica a ocorrência das palavras, seguido do TF, que cria uma melhor forma de ranqueamento ao contar as ocorrências das palavras para ranquear os documentos, TFIDF fica como o segundo melhor, pois, além do que os anteriores fazem, penaliza palavras que ocorrem com muita frequência nos documentos, e por fim o BM25 é mais preciso nos seus resultados, porque também normaliza o número de ocorrências das palavras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
