{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo para geração do indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordInfo:\n",
    "    'Classe que guarda informações sobre a palavra, como documentos em que ocorre, tf em cada documento e calculo de idf'\n",
    "\n",
    "    def __init__(self, word) : # Contrutor da classe recebe apenas a palavra em questão\n",
    "        self.word = word\n",
    "        self.idf = 0\n",
    "        self.docs = {} # Dicionario que mapeia doc_id ao tf da palavra\n",
    "\n",
    "    def found(self, doc_id) : # Metodo que realiza a contagem do tf da palavra\n",
    "        if(doc_id in self.docs) : # Se o doc_id está mapeado, incrementa-o\n",
    "            self.docs[doc_id] += 1\n",
    "        else :\n",
    "            self.docs[doc_id] = 1 # Caso contrario, define-o como 1\n",
    "            \n",
    "    def calculateIDF(self, totaldocs) : # Metodo de calculo do idf, recebendo o total de documentos\n",
    "        df = len(self.docs) # Numero de documentos em que a palavra ocorre \n",
    "        if (df > 0) :\n",
    "            self.idf = math.log((totaldocs + 1)/df)\n",
    "            \n",
    "    def getIds(self) : # Metodo que retorna todos os doc_ids em que a palavra ocorre\n",
    "        return list(self.docs.keys())\n",
    "    \n",
    "    def getTf(self, doc_id) : # Metodo que retorna o tf da palavra em um documento, ou 0 caso não ocorra\n",
    "        return self.docs.get(doc_id, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela = pandas.read_csv('estadao_noticias_eleicao.csv')\n",
    "tabela.fillna('', inplace=True) # Preenchendo os campos vazios da tabela com ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = {} # Dicionario/Mapa que representa o indice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = {} # Dicionario que guarda os documentos e seus tamanhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, linha in tabela.iterrows() : # Iterando sobre as noticias no arquivo\n",
    "    id = linha['idNoticia'] # Recuperando o idNoticia da noticia atual\n",
    "    texto = nltk.word_tokenize(linha['titulo'] + ' ' + linha['subTitulo'] + ' ' + linha['conteudo']) # Tokenização do texto\n",
    "    documentos[id] = len(texto) # Mapeamento do documento com seu tamanho\n",
    "    for palavra in texto: # Iterando sobre as palavras na Noticia\n",
    "        if (palavra not in string.punctuation): # Só ocorre o mapeamento se a palavra não é uma pontuação\n",
    "            if (palavra.lower() not in mapa) : # Se a palavra ainda não foi mapeada, mapeia-a\n",
    "                mapa[palavra.lower()] = WordInfo(palavra.lower())\n",
    "            mapa[palavra.lower()].found(id) # Contabiliza a ocorrencia da palavra no documento atual\n",
    "\n",
    "for k in mapa.keys() : # Laço para realizar o calculo dos idfs de cada palavra mapeada\n",
    "    mapa[k].calculateIDF(len(documentos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de Consultas Booleanas(And, Or e geral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchAnd(palavra1, palavra2) :\n",
    "    docs1 = mapa[palavra1.lower()].getIds() # Recupera todos as noticias em que \"palavra1\" ocorreu\n",
    "    docs2 = mapa[palavra2.lower()].getIds() # Recupera todos as noticias em que \"palavra2\" ocorreu\n",
    "    result = set() # Cria um conjunto vazio\n",
    "    result.update(docs1) # Preenche o conjunto com os ids das noticias que \"palavra1\" aparece\n",
    "    result = result.intersection(docs2) # Mantem no conjunto apenas os ids que as duas palavras ocorrem.\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchOr(palavra1, palavra2) :\n",
    "    docs1 = mapa[palavra1.lower()].getIds() # Recupera todos as noticias em que \"palavra1\" ocorreu\n",
    "    docs2 = mapa[palavra2.lower()].getIds() # Recupera todos as noticias em que \"palavra2\" ocorreu\n",
    "    result = set() # Cria um conjunto vazio\n",
    "    result.update(docs1) # Preenche o conjunto com os ids das noticias que \"palavra1\" aparece\n",
    "    result.update(docs2) # Preenche o conjunto com os ids das noticias que \"palavra2\" aparece, por ser conjunto as duplicadas são eliminadas\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(consulta) :\n",
    "    partes = consulta.split(' ')\n",
    "    if (len(partes) < 2) : # Se a consulta só tem uma palavra\n",
    "        return mapa[partes[0].lower()].getIds() # Recupera os ids que a palavra aparece\n",
    "    elif (partes[1].upper() == 'AND') : # Se é uma consulta AND\n",
    "        return searchAnd(partes[0], partes[2]) # Chama a função de consulta AND\n",
    "    elif (partes[1].upper() == 'OR') : # Se é uma consulta OR\n",
    "        return searchOr(partes[0], partes[2]) # Chama a função de consulta OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de Consultas Vetoriais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_binaria(consulta) :\n",
    "    palavras = consulta.split(' ') # Quebrando a consulta em palavras\n",
    "    relevant_docs = set(mapa[palavras[0]].getIds()) # Inicia o conjunto de documentos relevantes\n",
    "    # Laço que realiza interseção dos conjuntos, para mantes apenas documentos em que todas as palavras a consulta ocorre\n",
    "    for i in range(1, len(palavras)) :\n",
    "        relevant_docs = relevant_docs.intersection(set(mapa[palavras[i]].getIds()))\n",
    "    # Como é busca binaria, apenas retorna os primeiros 5 documentos que contem todas as palavras\n",
    "    return list(map(str, relevant_docs))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_tf(consulta) :\n",
    "    palavras = consulta.split(' ') # Quebrando a consulta em palavras\n",
    "    relevant_docs = set(mapa[palavras[0]].getIds()) # Inicia o conjunto de documentos relevantes\n",
    "    # Laço que realiza interseção dos conjuntos, para mantes apenas documentos em que todas as palavras a consulta ocorre\n",
    "    for i in range(1, len(palavras)) :\n",
    "        relevant_docs = relevant_docs.intersection(set(mapa[palavras[i]].getIds()))\n",
    "    result = [] # Lista que será gerado o resultado\n",
    "    for doc_id in relevant_docs : # Para cada documento relevante\n",
    "        scores = [mapa[w].getTf(doc_id) for w in palavras] # Obtem os tfs de cada palavra da consulta\n",
    "        # Cria uma tupla (score, doc_id) somando os tfs obtidos e coloca na lista\n",
    "        score_id = (sum(scores), doc_id)\n",
    "        result.append(score_id)\n",
    "    # Ordena do maior para o menor, por ser tupla, considera apenas o primeiro elemento para ordenar (o score)\n",
    "    result = sorted(result, reverse=True) \n",
    "    result = [str(t[1]) for t in result] # A lista passa a ser apenas dos doc_ids como strings (por causa da função mapk)\n",
    "    return result[:5] # Retorna os 5 primeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_tfidf(consulta) :\n",
    "    palavras = consulta.split(' ') # Quebrando a consulta em palavras\n",
    "    relevant_docs = set(mapa[palavras[0]].getIds()) # Inicia o conjunto de documentos relevantes\n",
    "    # Laço que realiza interseção dos conjuntos, para mantes apenas documentos em que todas as palavras a consulta ocorre\n",
    "    for i in range(1, len(palavras)) :\n",
    "        relevant_docs = relevant_docs.intersection(set(mapa[palavras[i]].getIds()))\n",
    "    result = [] # Lista que será gerado o resultado\n",
    "    for doc_id in relevant_docs : # Para cada documento relevante\n",
    "        scores = [mapa[w].getTf(doc_id) * mapa[w].idf for w in palavras] # Calcula tf * idf de cada palavra da consulta\n",
    "        # Cria uma tupla (score, doc_id) somando os resultados obtidos e coloca na lista\n",
    "        score_id = (sum(scores), doc_id)\n",
    "        result.append(score_id)\n",
    "    # Ordena do maior para o menor, por ser tupla, considera apenas o primeiro elemento para ordenar (o score)\n",
    "    result = sorted(result, reverse=True)\n",
    "    result = [str(t[1]) for t in result] # A lista passa a ser apenas dos doc_ids como strings (por causa da função mapk)\n",
    "    return result[:5] # Retorna os 5 primeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_bm25(consulta) :\n",
    "    k = 6 # 6 foi o valor de K que maximizou o resultado da função mapk\n",
    "    palavras = consulta.split(' ') # Quebrando a consulta em palavras\n",
    "    relevant_docs = set(mapa[palavras[0]].getIds()) # Inicia o conjunto de documentos relevantes\n",
    "    # Laço que realiza interseção dos conjuntos, para mantes apenas documentos em que todas as palavras a consulta ocorre\n",
    "    for i in range(1, len(palavras)) :\n",
    "        relevant_docs = relevant_docs.intersection(set(mapa[palavras[i]].getIds()))\n",
    "    result = [] # Lista que será gerado o resultado\n",
    "    for doc_id in relevant_docs : # Para cada documento relevante\n",
    "        # Calcula tf*(k+1)/(tf + k) * idf de cada palavra da consulta\n",
    "        scores = [(mapa[w].getTf(doc_id)*(k+1))/(mapa[w].getTf(doc_id) + k) * mapa[w].idf for w in palavras]\n",
    "        # Cria uma tupla (score, doc_id) somando os resultados obtidos e coloca na lista\n",
    "        score_id = (sum(scores), doc_id)\n",
    "        result.append(score_id)\n",
    "    # Ordena do maior para o menor, por ser tupla, considera apenas o primeiro elemento para ordenar (o score)\n",
    "    result = sorted(result, reverse=True)\n",
    "    result = [str(t[1]) for t in result] # A lista passa a ser apenas dos doc_ids como strings (por causa da função mapk)\n",
    "    return result[:5] # Retorna os 5 primeiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação Buscas Vetoriais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da função de comparação, Leitura do gabarito e realização das consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito = pandas.read_csv('gabarito.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaria_result, tf_result, tfidf_result, bm25_result = [], [], [], []\n",
    "for consulta in gabarito.str_busca :\n",
    "    binaria_result.append(busca_binaria(consulta))\n",
    "    tf_result.append(busca_tf(consulta))\n",
    "    tfidf_result.append(busca_tfidf(consulta))\n",
    "    bm25_result.append(busca_bm25(consulta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mapk Busca Binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(gabarito.busca_binaria, binaria_result, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mapk Busca TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9199999999999999"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(gabarito.tf, tf_result, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mapk TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253333333333334"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(gabarito.tfidf, tfidf_result, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mapk BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7626666666666667"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(gabarito.bm25, bm25_result, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Do melhor ao pior, como se saíram os modelos? Justifique sua resposta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparado ao gabarito:\n",
    "    1. Vetor binario\n",
    "    2. TF\n",
    "    3. BM25\n",
    "    4. TF-IDF\n",
    "Nos meus testes, acredito que seja simplesmente porque alguns documentos tem a mesma pontuação e a ordem ficou invertida comparado ao gabarito, fora isso, o BM25 parece melhor nos resultados, seguido por TF-IDF, TF e vetor binario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
