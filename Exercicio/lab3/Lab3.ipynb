{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de Recomendação - Notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordInfo:\n",
    "    'Classe que guarda informações sobre a palavra, como documentos em que ocorre, tf em cada documento e calculo de idf'\n",
    "\n",
    "    def __init__(self, word) : # Contrutor da classe recebe apenas a palavra em questão\n",
    "        self.word = word\n",
    "        self.idf = 0\n",
    "        self.docs = {} # Dicionario que mapeia doc_id ao tf da palavra\n",
    "\n",
    "    '''Incrementa o TF da palavra em um documento'''\n",
    "    def found(self, doc_id) : # Metodo que realiza a contagem do tf da palavra\n",
    "        if(doc_id in self.docs) : # Se o doc_id está mapeado, incrementa-o\n",
    "            self.docs[doc_id] += 1\n",
    "        else :\n",
    "            self.docs[doc_id] = 1 # Caso contrario, define-o como 1\n",
    "            \n",
    "    def calculateIDF(self, totaldocs) : # Metodo de calculo do idf, recebendo o total de documentos\n",
    "        df = len(self.docs) # Numero de documentos em que a palavra ocorre \n",
    "        if (df > 0) :\n",
    "            self.idf = math.log(((totaldocs + 1)/df))\n",
    "            \n",
    "    def getIds(self) : # Metodo que retorna todos os doc_ids em que a palavra ocorre\n",
    "        return list(self.docs.keys())\n",
    "    \n",
    "    def getTf(self, doc_id) : # Metodo que retorna o tf da palavra em um documento, ou 0 caso não ocorra\n",
    "        return self.docs.get(doc_id, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados e selecionando os conjuntos de treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"estadao_noticias_eleicao.csv\", encoding=\"utf-8\")\n",
    "data.fillna('', inplace=True) # Preenchendo os campos vazios da tabela com ''\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "data['tokenized_text'] = data.apply(lambda row: tokenizer.tokenize(row['titulo'] + ' ' + row['subTitulo'] + ' ' + row['conteudo']), axis=1)\n",
    "\n",
    "train = data.sample(frac=0.8)\n",
    "train.to_csv('tain_set.csv')\n",
    "validation = data.drop(train.index)\n",
    "validation.to_csv('validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {} # Vocabulario do conjunto de treinamento\n",
    "docs = {} # Vetores dos documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montagem do vocabulário e vetores dos documentos do conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows() :\n",
    "    id = row['idNoticia']\n",
    "    text = row['tokenized_text']\n",
    "    docs[id] = {}\n",
    "    for word in text:\n",
    "        if (word not in string.punctuation):\n",
    "            word_l = word.lower()\n",
    "            if (word_l not in vocab) :\n",
    "                vocab[word_l] = WordInfo(word_l)\n",
    "            vocab[word_l].found(id)\n",
    "            docs[id][word_l] = 1\n",
    "            \n",
    "# Calculo dos idfs de cada palavra mapeada e atualização dos vetores dos documentos\n",
    "for word in vocab.keys() : \n",
    "    vocab[word].calculateIDF(len(docs))\n",
    "    idf = vocab[word].idf\n",
    "    for doc_i in docs.keys() :\n",
    "        if (word in docs[doc_i]) :\n",
    "            docs[doc_i][word] = vocab[word].getTf(doc_i) * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17335698366910907\n"
     ]
    }
   ],
   "source": [
    "test = {w:vocab[w].idf for w in vocab.keys()}\n",
    "np.save('dicts.npy', (docs, test))\n",
    "\n",
    "d, v = np.load('dicts.npy')\n",
    "\n",
    "print(v['no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v == test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções para calcular a similaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula a similaridade entre 2 documentos, representados como um vetor, atravez do produto escalar entre os vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(docQ, docI) :\n",
    "    score = 0\n",
    "    for word in docQ.keys() :\n",
    "        score += docQ[word] * docI.get(word, 0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforma o documento em vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docVect(index) :\n",
    "    vect = {}\n",
    "    text = data[data.idNoticia == index].iloc[0]['tokenized_text']\n",
    "    for word in text:\n",
    "        if (word not in string.punctuation):\n",
    "            word_l = word.lower()\n",
    "            if (word_l not in vect) :\n",
    "                vect[word_l] = 0\n",
    "            if (word_l in vocab) :\n",
    "                vect[word_l] += vocab[word_l].idf\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula os 5 vizinhos mais próximos de um documento passado através do idNoticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5(index) :\n",
    "    docQ = docVect(index)\n",
    "    top = [(id_doc, similarity(docQ, docs[id_doc])) for id_doc in list(docs.keys())[:5]]\n",
    "    top = sorted(top, reverse=True, key=lambda tup: tup[1])\n",
    "    for i in list(docs.keys())[5:]:\n",
    "        sim = similarity(docQ, docs[i])\n",
    "        j = 4\n",
    "        while (sim > top[j][1] and j >= 0) :\n",
    "            j -= 1\n",
    "        top.insert(j+1, (i, sim))\n",
    "        top = top[:5]\n",
    "    return [t[0] for t in top[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new(index) :\n",
    "    doc = {}\n",
    "    data_doc = data[data.idNoticia == index].iloc[0]\n",
    "    doc['ID'] = str(data_doc['idNoticia'])\n",
    "    doc['Titulo'] = str(data_doc['titulo'])\n",
    "    doc['SubTitulo'] = str(data_doc['subTitulo'])\n",
    "    doc['Conteudo'] = str(data_doc['conteudo'])[:200] + '...'\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_5_neighbors(index) :\n",
    "    top = top5(index)\n",
    "    neighbors = []\n",
    "    for newID in top:\n",
    "        doc = get_new(newID)\n",
    "        neighbors.append(doc)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gera um idNoticia aleatório de um dos documentos no conjunto de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randValDoc() :\n",
    "    return validation.sample(1)['idNoticia'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para o documento 5024 os visinhos mais próximos são: [5024, 7017, 6554, 7, 5129]\n",
      "Para o documento 5366 os visinhos mais próximos são: [5979, 6099, 5962, 5270, 4479]\n",
      "Para o documento 3801 os visinhos mais próximos são: [3801, 3942, 7, 2047, 6554]\n"
     ]
    }
   ],
   "source": [
    "val_doc = randValDoc()\n",
    "neighbors = top5(val_doc)\n",
    "print (\"Para o documento {} os visinhos mais próximos são: {}\".format(val_doc, neighbors))\n",
    "\n",
    "val_doc = randValDoc()\n",
    "neighbors = top5(val_doc)\n",
    "print (\"Para o documento {} os visinhos mais próximos são: {}\".format(val_doc, neighbors))\n",
    "\n",
    "val_doc = randValDoc()\n",
    "neighbors = top5(val_doc)\n",
    "print (\"Para o documento {} os visinhos mais próximos são: {}\".format(val_doc, neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': '52',\n",
       "  'Titulo': 'Ministério de Dilma: mediocridade é a regra',\n",
       "  'SubTitulo': 'Na segunda leva de indicados, a presidente prezou mais os laços políticos do que as habilidades técnicas ao escolher um',\n",
       "  'Conteudo': 'A presidente Dilma Rousseff anunciou ontem treze novos ministros. Somados aos quatro nomes divulgados em novembro, entre os quais os três da equipe econômica, a presidente já definiu 17 dos 39 assento...'},\n",
       " {'ID': '7',\n",
       "  'Titulo': 'Veja os desafios dos governadores que assumem nesta quinta',\n",
       "  'SubTitulo': '',\n",
       "  'Conteudo': 'No\\xa0Acre, governador reeleito quer erradicar analfabetismo  O governador reeleito Tião Viana (PT) já anunciou que uma das principais metas do segundo mandato é erradicar o analfabetismo. De acordo com ...'},\n",
       " {'ID': '54',\n",
       "  'Titulo': 'Dilma anuncia 13 novos ministros e amplia espaço do PMDB na Esplanada',\n",
       "  'SubTitulo': 'Para reforçar base no Congresso, presidente mantém loteamento entre partidos aliados, contempla legendas recém-criadas como o PROS, que assume o lugar do PT na Educação, e escolhe Jaques Wagner para a Defesa; falta confirmar titulares de 22 pastas',\n",
       "  'Conteudo': 'BRASÍLIA - Num processo de escolha que reedita o loteamento da Esplanada dos Ministérios como forma de reforçar a base governista no Congresso, a presidente Dilma Rousseff anunciou nesta terça-feira, ...'},\n",
       " {'ID': '6554',\n",
       "  'Titulo': 'Prévia de programa do PT expõe pressão por crescimento',\n",
       "  'SubTitulo': 'Diretrizes serão discutidas em encontro do partido na sexta-feira e no sábado; documento associa adversários a ‘politicas',\n",
       "  'Conteudo': 'Diretrizes serão discutidas em encontro do partido na sexta-feira e no sábado; documento associa adversários a ‘politicas privatistas’ Vera Rosa\\xa0 Brasília – Com o argumento de que não basta reeleger D...'},\n",
       " {'ID': '3942',\n",
       "  'Titulo': 'O novo cenário e a imagem de quem cobiça o eleitorado',\n",
       "  'SubTitulo': 'Com os três protagonistas de volta à rua após a morte de Campos, Dilma, Marina e Aécio expõem as estratégias para conquistar votos',\n",
       "  'Conteudo': 'A trágica morte de Eduardo Campos no dia 13 de agosto reconfigurou a disputa presidencial, colocando no páreo Marina Silva, uma candidata competitiva, e obrigou as campanhas petista e tucana a reavali...'}]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_5_neighbors(52)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
